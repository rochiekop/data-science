{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWS5ip241pD5"
   },
   "source": [
    "# Week 6 - Data Cleansing & Manipulation\n",
    "---\n",
    "\n",
    "Mentoring Session - Job Preparation Program - Pacmann AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pV-Ii5mMnqjF"
   },
   "outputs": [],
   "source": [
    "# Please load this library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ukEolUB1yrn"
   },
   "source": [
    "# Task 1. Merge Transactions Data Across Branches\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzE_XWI21zuP"
   },
   "source": [
    "## Task Descriptions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPBef9D62hYL"
   },
   "source": [
    "- Toko Serba Ada has several branches across the country.\n",
    "- Toko Serba Ada manager wants to merge the transactions data across branches.\n",
    "- Your task is to create a function to join multiple transaction files.\n",
    "- Download the transactions files [here](https://drive.google.com/drive/folders/1bJ5EWEHwx3xXlSLVyUYjjK2D6v_br-hb?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asGJB8Ki2fmr"
   },
   "source": [
    "## Detail function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRxWtTaX2iOb"
   },
   "source": [
    "- Create a function called by `import_data`.\n",
    "- The function only needs one input, `filenames` (`list`), a list of transactions data files.\n",
    "- The `import_data` function will join every data listed on the filenames as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYTm69lp25U7"
   },
   "source": [
    "## Examples\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZTNOp3227jJ"
   },
   "source": [
    "**Input**\n",
    "\n",
    "```python\n",
    "# Masukkan input\n",
    "filenames = [\n",
    "    'branch_A.xlsx',\n",
    "    'branch_B.csv',\n",
    "    'branch_C.csv'\n",
    "]\n",
    "\n",
    "# Import data\n",
    "data = import_data(filenames = filenames)\n",
    "\n",
    "# Validasi hasil\n",
    "print('Data shape:', data.shape)\n",
    "data.head(5)\n",
    "```\n",
    "\n",
    "**Output**\n",
    "```\n",
    "Data shape: (1000, 17)\n",
    "```\n",
    "<img src=\"https://drive.google.com/uc?id=10VjyzDyInVbeqb6E5a0AlnU5DuZCx3ef\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jupheDDg4UY8"
   },
   "source": [
    "## Answer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_wfnkWT4Wdn"
   },
   "source": [
    "- Provide the code for solving the problem\n",
    "- **Make sure your function follows the `Detail Function`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "xl0q4hGyk84P"
   },
   "outputs": [],
   "source": [
    "# Write your function in here\n",
    "def import_data(filenames):\n",
    "    \"\"\" \n",
    "        This function is only to concatenate the rows of data\n",
    "        and assume the column has the same name, length and same ordered\n",
    "    \"\"\"\n",
    "    # create an Empty DataFrame object\n",
    "    l_data = []\n",
    "    if filenames:\n",
    "        for item in filenames:\n",
    "            data = read_data(item)\n",
    "            l_data.append(data)\n",
    "        data = pd.concat(l_data, axis=0, ignore_index=True)\n",
    "        return data\n",
    "    return \"Empty Data\"\n",
    "\n",
    "    \n",
    "def read_data(filename):\n",
    "    _,file_extension= os.path.splitext(filename)\n",
    "    r_data = check_format(file_extension,filename)    \n",
    "    if not r_data.empty:\n",
    "        return r_data\n",
    "    \n",
    "    print(f\"Extention is not found : {file_extension}\")\n",
    "\n",
    "def check_format(f_extension,filename):\n",
    "    # Dictionary of functions to read files based on extension\n",
    "    s_format = {\n",
    "        \".csv\": lambda: pd.read_csv(filename, encoding='utf8', sep=';'),\n",
    "        \".xlsx\": lambda: pd.read_excel(filename)\n",
    "    }\n",
    "    \n",
    "    # Check if the extension is supported\n",
    "    if f_extension in s_format:\n",
    "        return s_format[f_extension]()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {f_extension}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1000, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice ID</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>Customer type</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Product line</th>\n",
       "      <th>Unit price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Tax 5%</th>\n",
       "      <th>Total</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Payment</th>\n",
       "      <th>cogs</th>\n",
       "      <th>gross margin percentage</th>\n",
       "      <th>gross income</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>750-67-8428</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>74.69</td>\n",
       "      <td>7</td>\n",
       "      <td>26.1415</td>\n",
       "      <td>548.9715</td>\n",
       "      <td>1/5/2019</td>\n",
       "      <td>13:08</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>522.83</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>26.1415</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>631-41-3108</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Home and lifestyle</td>\n",
       "      <td>46.33</td>\n",
       "      <td>7</td>\n",
       "      <td>16.2155</td>\n",
       "      <td>340.5255</td>\n",
       "      <td>3/3/2019</td>\n",
       "      <td>13:23</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>324.31</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>16.2155</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>123-19-1176</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Member</td>\n",
       "      <td>Male</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>58.22</td>\n",
       "      <td>8</td>\n",
       "      <td>23.2880</td>\n",
       "      <td>489.0480</td>\n",
       "      <td>1/27/2019</td>\n",
       "      <td>20:33</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>465.76</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>23.2880</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>373-73-7910</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sports and travel</td>\n",
       "      <td>86.31</td>\n",
       "      <td>7</td>\n",
       "      <td>30.2085</td>\n",
       "      <td>634.3785</td>\n",
       "      <td>2/8/2019</td>\n",
       "      <td>10:37</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>604.17</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>30.2085</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>355-53-5943</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>Electronic accessories</td>\n",
       "      <td>68.84</td>\n",
       "      <td>6</td>\n",
       "      <td>20.6520</td>\n",
       "      <td>433.6920</td>\n",
       "      <td>2/25/2019</td>\n",
       "      <td>14:36</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>413.04</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>20.6520</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Invoice ID Branch    City Customer type  Gender            Product line  \\\n",
       "0  750-67-8428      A  Yangon        Member  Female       Health and beauty   \n",
       "1  631-41-3108      A  Yangon        Normal    Male      Home and lifestyle   \n",
       "2  123-19-1176      A  Yangon        Member    Male       Health and beauty   \n",
       "3  373-73-7910      A  Yangon        Normal    Male       Sports and travel   \n",
       "4  355-53-5943      A  Yangon        Member  Female  Electronic accessories   \n",
       "\n",
       "   Unit price  Quantity   Tax 5%     Total       Date   Time      Payment  \\\n",
       "0       74.69         7  26.1415  548.9715   1/5/2019  13:08      Ewallet   \n",
       "1       46.33         7  16.2155  340.5255   3/3/2019  13:23  Credit card   \n",
       "2       58.22         8  23.2880  489.0480  1/27/2019  20:33      Ewallet   \n",
       "3       86.31         7  30.2085  634.3785   2/8/2019  10:37      Ewallet   \n",
       "4       68.84         6  20.6520  433.6920  2/25/2019  14:36      Ewallet   \n",
       "\n",
       "     cogs  gross margin percentage  gross income  Rating  \n",
       "0  522.83                 4.761905       26.1415     9.1  \n",
       "1  324.31                 4.761905       16.2155     7.4  \n",
       "2  465.76                 4.761905       23.2880     8.4  \n",
       "3  604.17                 4.761905       30.2085     5.3  \n",
       "4  413.04                 4.761905       20.6520     5.8  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Masukkan input\n",
    "filenames = [\n",
    "    'branch_A.xlsx',\n",
    "    'branch_B.csv',\n",
    "    'branch_C.csv'\n",
    "]\n",
    "\n",
    "# Import data\n",
    "data = import_data(filenames = filenames)\n",
    "\n",
    "# Validasi hasil\n",
    "print('Data shape:', data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcUiUO9e419L"
   },
   "source": [
    "# Task 2. Get the Unwatched Movie\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Q89NV-v5Upz"
   },
   "source": [
    "## Task Descriptions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6tt_INg5V6v"
   },
   "source": [
    "- You are a data analyst in a movie industry\n",
    "- The product team ask you to recommend something new for a user to watch.\n",
    "- You easily think of recommending the unwatched movies for a specific user Id.\n",
    "- To recommend the unwatched movies nicely in the website, the engineering team needs you to return 3 things\n",
    "  - `movieId`\n",
    "  - `title`\n",
    "  - `genres`\n",
    "- Your task is to **create a function** to return the unwatched movies from a specific user id based on engineering team requirements.\n",
    "- You can download your dataset in [here](https://drive.google.com/drive/folders/1HSa7KStIlOS7rXY5ykwGZR6l9P-AJrKj?usp=sharing).\n",
    "  - `ratings.csv` contains the user activity after watching movies, i.e. give a rating to each movie they watched.\n",
    "  - `movies.csv` contains the movie metadata (movie ID, title, and genre)\n",
    "- The dataset originally comes from **MovieLens**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uos19MkT6tpb"
   },
   "source": [
    "## Detail function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9fqlTdW6vAy"
   },
   "source": [
    "- Create a function called `get_unwatched_movie`\n",
    "- The function needs two input\n",
    "  - `userId` (`int`): The targeted user ID\n",
    "  - `config` (`dict`): The configuration files where the engineering team store the user-data and movie metadata. Example\n",
    "\n",
    "  ```python\n",
    "  config = {\n",
    "      'path': {\n",
    "          'user_data': 'ratings.csv',\n",
    "          'metadata': 'movies.csv'\n",
    "      }\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- The function return an output in pandas DataFrame type with `movieId` as an index and two columns of `title` and `genres`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMDNsRVc7qM7"
   },
   "source": [
    "## Examples\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc6xkzW77vAU"
   },
   "source": [
    "**Define the Configuration Variable**\n",
    "\n",
    "```python\n",
    "# Define CONFIG variable\n",
    "CONFIG = {\n",
    "    'path': {\n",
    "        'user_data': 'ratings.csv',\n",
    "        'metadata': 'movies.csv'\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2-pjdaf7617"
   },
   "source": [
    "---\n",
    "**Input 1**\n",
    "\n",
    "```python\n",
    "# Cari unwatched data untuk userId = 3\n",
    "unwatched_data = get_unwatched_movie(userId = 3,\n",
    "                                     config = CONFIG)\n",
    "\n",
    "print('Data shape:', unwatched_data.shape)\n",
    "unwatched_data.sample(n=5, random_state=42)\n",
    "```\n",
    "\n",
    "**Output 1**\n",
    "```\n",
    "Data shape: (9703, 2)\n",
    "```\n",
    "<img src=\"https://drive.google.com/uc?id=18R0Ym9NplzBnu12hBU10DR8tgFBiQhp6\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezWDg4vz8ayo"
   },
   "source": [
    "---\n",
    "**Input 2**\n",
    "\n",
    "```python\n",
    "# Cari unwatched data untuk userId = 10\n",
    "unwatched_data = get_unwatched_movie(userId = 10,\n",
    "                                     config = CONFIG)\n",
    "\n",
    "print('Data shape:', unwatched_data.shape)\n",
    "unwatched_data.sample(n=5, random_state=42)\n",
    "```\n",
    "\n",
    "**Output 2**\n",
    "```\n",
    "Data shape: (9602, 2)\n",
    "```\n",
    "<img src=\"https://drive.google.com/uc?id=1m8igXpZ5zS75ioV1tT8gIpLvtrh7TdrK\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4huTp6FA8dTP"
   },
   "source": [
    "---\n",
    "**Input 3**\n",
    "\n",
    "```python\n",
    "# Cari unwatched data untuk userId = 3\n",
    "unwatched_data = get_unwatched_movie(userId = 3,\n",
    "                                     config = CONFIG)\n",
    "\n",
    "print('Data shape:', unwatched_data.shape)\n",
    "unwatched_data.sample(n=5, random_state=42)\n",
    "```\n",
    "\n",
    "**Output 3**\n",
    "```\n",
    "Data shape: (9402, 2)\n",
    "```\n",
    "<img src=\"https://drive.google.com/uc?id=1R-BLxcY8Bf3XUxB2Ikf95wafj_1iRNCg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z-ME-8zAcmy"
   },
   "source": [
    "## Answer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-t9K53MAcm1"
   },
   "source": [
    "- Provide the code for solving the problem\n",
    "- **Make sure your function follows the `Detail Function`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "v4zhCoX1r-FP"
   },
   "outputs": [],
   "source": [
    "# Write your function in here\n",
    "def get_unwatched_movie(userId,config):\n",
    "    try:\n",
    "        if userId:\n",
    "            df = read_data(config)\n",
    "            ratings = df['user_data']\n",
    "            filter_user = ratings[ratings['userId'] == userId]\n",
    "            merge_movies = df['metadata'].merge(filter_user,how='left',on='movieId')\n",
    "            new_df = merge_movies[merge_movies['userId'].isnull()]\n",
    "            unwatched_movies = transform_df(new_df)\n",
    "            return unwatched_movies\n",
    "    except Exception as err:\n",
    "        raise ValueError(str(err))\n",
    "        \n",
    "        \n",
    "def read_data(config):\n",
    "    try:    \n",
    "        path_data = {}\n",
    "        data = config['path']\n",
    "        for key,filename in data.items():\n",
    "            _,file_extension= os.path.splitext(filename)\n",
    "            path_data[key]= check_format(file_extension,filename)    \n",
    "        if path_data:\n",
    "            return path_data\n",
    "\n",
    "        print(f\"Extention is not found : {file_extension}\")\n",
    "\n",
    "    except Exception as err:\n",
    "        raise ValueError(str(err))\n",
    "        \n",
    "def check_format(f_extension,filename):\n",
    "    try:    \n",
    "        # Dictionary of functions to read files based on extension\n",
    "        s_format = {\n",
    "            \".csv\": lambda: pd.read_csv(filename),\n",
    "            \".xlsx\": lambda: pd.read_excel(filename)\n",
    "        }\n",
    "\n",
    "        # Check if the extension is supported\n",
    "        if f_extension in s_format:\n",
    "            return s_format[f_extension]()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {f_extension}\")\n",
    "    except Exception as err:\n",
    "        raise ValueError(str(err))\n",
    "\n",
    "def transform_df(df):\n",
    "    try:\n",
    "        data = df[[\"movieId\",\"title\",\"genres\"]]\n",
    "        data.set_index(\"movieId\",inplace=True)\n",
    "        return data\n",
    "    except Exception as err:\n",
    "        raise ValueError(str(err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (9602, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1797</td>\n",
       "      <td>Everest (1998)</td>\n",
       "      <td>Documentary|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179819</td>\n",
       "      <td>Star Wars: The Last Jedi (2017)</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77266</td>\n",
       "      <td>Disgrace (2008)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26003</td>\n",
       "      <td>Night and Fog (Nuit et brouillard) (1955)</td>\n",
       "      <td>Crime|Documentary|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54686</td>\n",
       "      <td>Last Legion, The (2007)</td>\n",
       "      <td>Action|Adventure|Fantasy|War</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "movieId                                              \n",
       "1797                                Everest (1998)   \n",
       "179819             Star Wars: The Last Jedi (2017)   \n",
       "77266                              Disgrace (2008)   \n",
       "26003    Night and Fog (Nuit et brouillard) (1955)   \n",
       "54686                      Last Legion, The (2007)   \n",
       "\n",
       "                                  genres  \n",
       "movieId                                   \n",
       "1797                    Documentary|IMAX  \n",
       "179819   Action|Adventure|Fantasy|Sci-Fi  \n",
       "77266                              Drama  \n",
       "26003              Crime|Documentary|War  \n",
       "54686       Action|Adventure|Fantasy|War  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define CONFIG variable\n",
    "CONFIG = {\n",
    "    'path': {\n",
    "        'user_data': 'ratings.csv',\n",
    "        'metadata': 'movies.csv'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Cari unwatched data untuk userId = 3\n",
    "unwatched_data = get_unwatched_movie(userId = 10,\n",
    "                                     config = CONFIG)\n",
    "\n",
    "print('Data shape:', unwatched_data.shape)\n",
    "unwatched_data\n",
    "unwatched_data.sample(n=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8ZTkUY1DXce"
   },
   "source": [
    "# Task 3. Get the House Recommendation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olcW2W8shH7P"
   },
   "source": [
    "## Task Descriptions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxZr9PFzhJSG"
   },
   "source": [
    "- Assume you work as a Data Analyst in Travelio.\n",
    "- The product team request you to give its users housing recommendations based on their current location and housing preferences.\n",
    "- Please create a function to answer the product team request.\n",
    "- You can find the dataset [here](https://drive.google.com/file/d/1D5phg8q0MiX4lRKlEaBWHT07MoEgEr28/view?usp=sharing).\n",
    "- **Note**: The dataset is scrapped by Pacmann from the Travelio website for educational purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ssd2XnS3iSrD"
   },
   "source": [
    "## Detail function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mE5cg8GxiTY2"
   },
   "source": [
    "- Create a function called by `get_user_recommendation` that return the top-$n$ housing recommendation for a specific user location & preferences sorted by the nearest distance between user location and house location.\n",
    "- The function needs three input, i.e.\n",
    "    - `n` (`int`): the maximum number of recommendation.\n",
    "    - `user_config` (`dict`): the user configuration data. It contains the user preferences and user current location.\n",
    "    - `data_config` (`dict`): the data configuration that contains the housing data path.\n",
    "- The output is a dataframe type with similar data columns to the dataset.\n",
    "---\n",
    "- We filter using 5 preferences, that is\n",
    "  - `property_type`. It should return `apartment` or `house`.\n",
    "  - `size`. It should return houses that is **larger than or equal to** the given `size`.\n",
    "  - `capacity`. It should return houses that is **more than or equal to** the given `capacity`.\n",
    "  - `is_furnished`. It should return `Full Furnished` or `Unfurnished`.\n",
    "  - `yearly_price`. It should return houses that is **less than or equal to** the given `yearly_price` rent\n",
    "- If user fill nothing (`None`), then you should not filter anything.\n",
    "---\n",
    "- Please use the **Haversine** distance to calculate the distance between user and houses.\n",
    "- We intentionally not giving you the Haversine distance formula. Please explore it by yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVyoxliVku2i"
   },
   "source": [
    "## Examples\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OdE7AAzlAP8"
   },
   "source": [
    "---\n",
    "**Input 1**\n",
    "\n",
    "```python\n",
    "# Define the user data\n",
    "user_config = {\n",
    "    'preferences': {\n",
    "        'property_type': None,\n",
    "        'size': 30.0,\n",
    "        'capacity': 2,\n",
    "        'is_furnished': 'Full Furnished',\n",
    "        'yearly_price': 50000000\n",
    "    },\n",
    "    'location': {\n",
    "        # Dekat Bintaro Plaza\n",
    "        'latitude': -6.2734,\n",
    "        'longitude': 106.7364\n",
    "    }\n",
    "}\n",
    "\n",
    "data_config = {\n",
    "    'path': 'travelio_dki_jakarta.csv'\n",
    "}\n",
    "\n",
    "# Run the function\n",
    "user_recommendation = get_user_recommendation(n = 10,\n",
    "                                              user_config = user_config,\n",
    "                                              data_config = data_config)\n",
    "\n",
    "# Validate\n",
    "print('Data Shape:', user_recommendation.shape)\n",
    "user_recommendation\n",
    "```\n",
    "\n",
    "**Output 1**\n",
    "```\n",
    "Data Shape: (10, 16)\n",
    "```\n",
    "<img src=\"https://drive.google.com/uc?id=1Ek8VjhgOqWh18T1zEvn0b5zZIKlMt1wG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYjtpQ_HlBLv"
   },
   "source": [
    "---\n",
    "**Input 2**\n",
    "\n",
    "```python\n",
    "# Define the user data\n",
    "user_config = {\n",
    "    'preferences': {\n",
    "        'property_type': None,\n",
    "        'size': 45.0,\n",
    "        'capacity': 4,\n",
    "        'is_furnished': None,\n",
    "        'yearly_price': 25000000\n",
    "    },\n",
    "    'location': {\n",
    "        # Dekat Monumen Nasional (Monas)\n",
    "        'latitude': -6.1792,\n",
    "        'longitude': 106.8265\n",
    "    }\n",
    "}\n",
    "\n",
    "data_config = {\n",
    "    'path': 'travelio_dki_jakarta.csv'\n",
    "}\n",
    "\n",
    "# Run the function\n",
    "user_recommendation = get_user_recommendation(n = 10,\n",
    "                                              user_config = user_config,\n",
    "                                              data_config = data_config)\n",
    "\n",
    "# Validate\n",
    "print('Data Shape:', user_recommendation.shape)\n",
    "user_recommendation\n",
    "```\n",
    "\n",
    "**Output 2**\n",
    "```\n",
    "Data Shape: (10, 16)\n",
    "```\n",
    "<img src=\"https://drive.google.com/uc?id=14eIe-BjfjTM53Y3m9ObdoQ2nKVWgUGiY\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjkWBi07lB6-"
   },
   "source": [
    "---\n",
    "**Input 3**\n",
    "\n",
    "```python\n",
    "# Define the user data\n",
    "user_config = {\n",
    "    'preferences': {\n",
    "        'property_type': None,\n",
    "        'size': 60.0,\n",
    "        'capacity': 4,\n",
    "        'is_furnished': None,\n",
    "        'yearly_price': 25000000\n",
    "    },\n",
    "    'location': {\n",
    "        # Dekat Kota Tua Jakarta\n",
    "        'latitude': -6.1378,\n",
    "        'longitude': 106.8144\n",
    "    }\n",
    "}\n",
    "\n",
    "data_config = {\n",
    "    'path': 'travelio_dki_jakarta.csv'\n",
    "}\n",
    "\n",
    "# Run the function\n",
    "user_recommendation = get_user_recommendation(n = 10,\n",
    "                                              user_config = user_config,\n",
    "                                              data_config = data_config)\n",
    "\n",
    "# Validate\n",
    "print('Data Shape:', user_recommendation.shape)\n",
    "user_recommendation\n",
    "```\n",
    "\n",
    "**Output 3**\n",
    "```\n",
    "Data Shape: (6, 16)\n",
    "```\n",
    "<img src=\"https://drive.google.com/uc?id=1WAjuLElzpxuECoh8ArhD2XeWEj1T3blk\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HleIt4RmrZK"
   },
   "source": [
    "## Answer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygTl_yizmtaO"
   },
   "source": [
    "- Provide the code for solving the problem\n",
    "- **Make sure your function follows the `Detail Function`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "liakKidM_Aru"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".csv\n",
      "travelio_dki_jakarta.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[Errno 2] File b'travelio_dki_jakarta.csv' does not exist: b'travelio_dki_jakarta.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-070211b25095>\u001b[0m in \u001b[0;36mcheck_format\u001b[1;34m(f_extension, filename)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf_extension\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ms_format\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0ms_format\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf_extension\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-070211b25095>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         s_format = {\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;34m\".xlsx\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'travelio_dki_jakarta.csv' does not exist: b'travelio_dki_jakarta.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-070211b25095>\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_extension\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mpath_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcheck_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_extension\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-070211b25095>\u001b[0m in \u001b[0;36mcheck_format\u001b[1;34m(f_extension, filename)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [Errno 2] File b'travelio_dki_jakarta.csv' does not exist: b'travelio_dki_jakarta.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-070211b25095>\u001b[0m in \u001b[0;36mget_user_recommendation\u001b[1;34m(n, data_config)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-070211b25095>\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [Errno 2] File b'travelio_dki_jakarta.csv' does not exist: b'travelio_dki_jakarta.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-070211b25095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# Run the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m user_recommendation = get_user_recommendation(n = 10,\n\u001b[1;32m---> 49\u001b[1;33m                                               data_config = data_config)\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-070211b25095>\u001b[0m in \u001b[0;36mget_user_recommendation\u001b[1;34m(n, data_config)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [Errno 2] File b'travelio_dki_jakarta.csv' does not exist: b'travelio_dki_jakarta.csv'"
     ]
    }
   ],
   "source": [
    "# Write your function in here\n",
    "def get_user_recommendation(n,data_config):\n",
    "    try:\n",
    "        if n and data_config:\n",
    "            df = read_data(data_config)\n",
    "            return df\n",
    "    except Exception as err:\n",
    "        raise ValueError(str(err))\n",
    "        \n",
    "def read_data(config):\n",
    "    try:    \n",
    "        for _,filename in config.items():\n",
    "            _,file_extension= os.path.splitext(filename)\n",
    "            path_data= check_format(file_extension,filename)    \n",
    "        if path_data:\n",
    "            return path_data\n",
    "\n",
    "        print(f\"Extention is not found : {file_extension}\")\n",
    "\n",
    "    except Exception as err:\n",
    "        raise ValueError(str(err))\n",
    "        \n",
    "def check_format(f_extension,filename):\n",
    "    try:    \n",
    "        # Dictionary of functions to read files based on extension\n",
    "        print(f_extension)\n",
    "        print(filename)\n",
    "\n",
    "        s_format = {\n",
    "            \".csv\": lambda: pd.read_csv(filename),\n",
    "            \".xlsx\": lambda: pd.read_excel(filename)\n",
    "        }\n",
    "\n",
    "        # Check if the extension is supported\n",
    "        if f_extension in s_format:\n",
    "            return s_format[f_extension]()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {f_extension}\")\n",
    "    except Exception as err:\n",
    "        raise ValueError(str(err))\n",
    "        \n",
    "        \n",
    "data_config = {\n",
    "    'path': 'travelio_dki_jakarta.csv'\n",
    "}\n",
    "\n",
    "# Run the function\n",
    "user_recommendation = get_user_recommendation(n = 10,\n",
    "                                              data_config = data_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'travelio_dki_jakarta.csv' does not exist: b'travelio_dki_jakarta.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dadb2ca31cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"travelio_dki_jakarta.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'travelio_dki_jakarta.csv' does not exist: b'travelio_dki_jakarta.csv'"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv(\"travelio_dki_jakarta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r44bj8r2m5Qn"
   },
   "source": [
    "# Task 4. Export the Promising State\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za01chEo0cX4"
   },
   "source": [
    "## Task Descriptions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfqpPT5F0dbb"
   },
   "source": [
    "- Assumed you are a data analyst in Amazon.\n",
    "- Your supervisor ask you to export a promising state sales data based on its market share to a .csv files, thus each state representatives can analyst the sales data further.\n",
    "- A promising state is a state that has its market share bigger or equal to a specified threshold.\n",
    "- The market share of a specific state is defined as number of order on a specific state / total order.\n",
    "- Write a function to help your supervisor!\n",
    "- Download your data in [here](https://drive.google.com/file/d/1oRAPo7ZST2i_pHAIWP2_KoLraniUwyME/view?usp=sharing).\n",
    "- The actual data source is in [here](https://www.kaggle.com/datasets/thedevastator/unlock-profits-with-e-commerce-sales-data?select=Amazon+Sale+Report.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv_Mf9v01as-"
   },
   "source": [
    "## Detail function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwnE4aS81bc1"
   },
   "source": [
    "- Create a function called by `export_promising_state`\n",
    "- This function needs two inputs\n",
    "  - `config_file` (`dict`) contains the input and output path\n",
    "  - `thresh` (`float`) contains the given market share threshold.\n",
    "- This function returns nothing.\n",
    "- If you cannot find any promising state based on the given threshold, then print `No promising state`.\n",
    "- If you can find promising state,\n",
    "  - First, drop column `index` and `Unnamed: 22` from the promising data.\n",
    "  - Save the promising data with format: `folder_path` + `state-name` + `-sales-reports.csv`, e.g.: `sales_data/telangana-sales-reports.csv`\n",
    "  - Write the prompt after successfully exporting data that includes the state market share and state sales data shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akMPKhfH22cA"
   },
   "source": [
    "## Examples\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hG0MZ8-3Jam"
   },
   "source": [
    "**Define the Configuration Variable**\n",
    "\n",
    "```python\n",
    "# Define CONFIG variable\n",
    "config_file = {\n",
    "    'path': {\n",
    "        'input': 'Amazon Sale Report.csv',\n",
    "        'output': 'sales_data/'\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBZudV3I3Pb7"
   },
   "source": [
    "---\n",
    "**Input 1**\n",
    "\n",
    "```python\n",
    "# Input 1\n",
    "export_promising_state(config_file = config_file,\n",
    "                       thresh = 0.10)\n",
    "```\n",
    "\n",
    "**Output 1**\n",
    "```\n",
    "Data of state \"karnataka\" was successfully exported into \"sales_data/karnataka-sales-reports.csv\"\n",
    "  - State market share : 13.43 %\n",
    "  - Data shape         : (17326, 22)\n",
    "\n",
    "Data of state \"maharashtra\" was successfully exported into \"sales_data/maharashtra-sales-reports.csv\"\n",
    "  - State market share : 17.26 %\n",
    "  - Data shape         : (22260, 22)\n",
    "```\n",
    "\n",
    "Example of the created files: <br>\n",
    "<img src=\"https://drive.google.com/uc?id=1C1r8SKoRHbKX0upPl5VDrzuf4Mi0joiC\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTRSlJ5q3Tll"
   },
   "source": [
    "---\n",
    "**Input 2**\n",
    "\n",
    "```python\n",
    "# Input 2\n",
    "export_promising_state(config_file = config_file,\n",
    "                       thresh = 0.05)\n",
    "```\n",
    "\n",
    "**Output 2**\n",
    "```\n",
    "Data of state \"telangana\" was successfully exported into \"sales_data/telangana-sales-reports.csv\"\n",
    "  - State market share : 8.78 %\n",
    "  - Data shape         : (11330, 22)\n",
    "\n",
    "Data of state \"kerala\" was successfully exported into \"sales_data/kerala-sales-reports.csv\"\n",
    "  - State market share : 5.11 %\n",
    "  - Data shape         : (6585, 22)\n",
    "\n",
    "Data of state \"delhi\" was successfully exported into \"sales_data/delhi-sales-reports.csv\"\n",
    "  - State market share : 5.40 %\n",
    "  - Data shape         : (6967, 22)\n",
    "\n",
    "Data of state \"uttar pradesh\" was successfully exported into \"sales_data/uttar pradesh-sales-reports.csv\"\n",
    "  - State market share : 8.25 %\n",
    "  - Data shape         : (10638, 22)\n",
    "\n",
    "Data of state \"karnataka\" was successfully exported into \"sales_data/karnataka-sales-reports.csv\"\n",
    "  - State market share : 13.43 %\n",
    "  - Data shape         : (17326, 22)\n",
    "\n",
    "Data of state \"tamil nadu\" was successfully exported into \"sales_data/tamil nadu-sales-reports.csv\"\n",
    "  - State market share : 8.90 %\n",
    "  - Data shape         : (11483, 22)\n",
    "\n",
    "Data of state \"maharashtra\" was successfully exported into \"sales_data/maharashtra-sales-reports.csv\"\n",
    "  - State market share : 17.26 %\n",
    "  - Data shape         : (22260, 22)\n",
    "```\n",
    "\n",
    "Example of the created files: <br>\n",
    "<img src=\"https://drive.google.com/uc?id=1ujeDK87N4MLk1_9Uew4lkIeFA81_DtDw\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zffc2mVO3VZL"
   },
   "source": [
    "---\n",
    "**Input 3**\n",
    "\n",
    "```python\n",
    "# Input 3\n",
    "export_promising_state(config_file = config_file,\n",
    "                       thresh = 0.4)\n",
    "```\n",
    "\n",
    "**Output 3**\n",
    "```\n",
    "No promising state\n",
    "```\n",
    "<img src=\"\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd_cKbpD4LC-"
   },
   "source": [
    "## Answer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UarFLbE54LC_"
   },
   "source": [
    "- Provide the code for solving the problem\n",
    "- **Make sure your function follows the `Detail Function`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0FZ4PVcqMYc"
   },
   "outputs": [],
   "source": [
    "# Write your function in here\n",
    "# Psst.. You can build as many functions you need.\n",
    "#        Just make sure the function is\n",
    "#        - Modular\n",
    "#        - Clean (easy to read & with docstring)\n",
    "#        - Can be easily validated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__nUZINgiFuz"
   },
   "source": [
    "# Task 5.  Clean the AirBnB data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBioio27iFuz"
   },
   "source": [
    "## Task Descriptions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygmo2BIFiRoB"
   },
   "source": [
    "- You are given a dataset of guests and hosts of AirBnB.\n",
    "- This dataset contains the review given by a guest (`id`) to the listing.\n",
    "- You want to analyze the review given by the guests by `neighborhood group`.\n",
    "- But the data is not clean.\n",
    "- Please clean the data by\n",
    "  1. Dropping data with missing value\n",
    "  2. Removing the unconsitency in `neighborhood group`\n",
    "  3. Dropping the listing outliers/anomaly.\n",
    "    - listing with anomaly rent price (please use IQR method to filter the outlier).\n",
    "    - listing with anomaly `availability 365` (`availability 365` is defined as an indicator of the total number of days the listing is available for during the year)\n",
    "  4. Drop duplicates data (if any)\n",
    "\n",
    "**Dataset**\n",
    "- Please download the dataset in [here](https://drive.google.com/file/d/19zOwcAkd7lTC_djAMgc5u1B7I2iPj5ek/view?usp=sharing)\n",
    "- The actual data source is [here](https://www.kaggle.com/datasets/arianazmoudeh/airbnbopendata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctEeOVMsiFu0"
   },
   "source": [
    "## Expected Output\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krzBhgNPuQyD"
   },
   "source": [
    "The output should be:\n",
    "```\n",
    "Clean data shape: (98174, 26)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd8KjEm6uS5b"
   },
   "source": [
    "With the sample of the clean data\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1ZmVMW41RbxCuKUcafic5CL9E0JAemdNk\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfXLyzAziFu2"
   },
   "source": [
    "## Answer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTrqm4UjiFu2"
   },
   "source": [
    "- Provide the code for getting the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91DWfTD66urp"
   },
   "outputs": [],
   "source": [
    "# Write your code in here\n",
    "# Provide your code with sufficient comment on the wrangling processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO-1ez6Ypm8y"
   },
   "source": [
    "# Task 6. Calculate Month-Over-Month Percentage Change in Sales\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liOhVqR0pm8z"
   },
   "source": [
    "## Task Descriptions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB7TDwY34sML"
   },
   "source": [
    "- Given a dataset of sales report by date, **calculate the mont-over-month percentage change in sales**.\n",
    "- The ouput should include the year-month date (YYYY-MM) and percentage change, rounded to the 2nd decimal point, and sorted by `order-date` in ascending order.\n",
    "- The percentage change column will be populated from the 2nd month forward and can be calculated as\n",
    "$$\n",
    "\\cfrac\n",
    "{(\\text{this month's sales - last month's sales})}\n",
    "{\\text{last month's sales}} \\cdot 100\\%\n",
    "$$\n",
    "\n",
    "**Dataset**\n",
    "- Please download the dataset in [here](https://drive.google.com/file/d/13QxDig8cXrT5ErVO2tytYdmksjbH3tep/view?usp=sharing)\n",
    "- The actual data source is [here](https://www.kaggle.com/datasets/apoorvaappz/global-super-store-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IH8qSK1EcmE5"
   },
   "source": [
    "## Expected Output\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70br3xsm1ltM"
   },
   "source": [
    "The output should be:\n",
    "\n",
    "```\n",
    "Data Shape: (48, 3)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIThYASzE5LE"
   },
   "source": [
    "With the first 12 entry of the final data is\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1Qcj_OUVOqfFCwbau0XUJK9URL3BrX86u\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fnzs051zpm80"
   },
   "source": [
    "## Answer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2REDDwMpm81"
   },
   "source": [
    "- Provide the code for getting the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PPNoC7YFPm2"
   },
   "outputs": [],
   "source": [
    "# Write your code in here\n",
    "# Provide your code with sufficient comment on the wrangling processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZghty1lvwEZ"
   },
   "source": [
    "# Task 7. Time to Purchase Duration\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naXaeZLDvwEa"
   },
   "source": [
    "## Task Descriptions\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K-S6Cc_HL8E"
   },
   "source": [
    "- Given a dataset of an e-commerce events history in Electronic shop.\n",
    "- Your task is to\n",
    "  1. **calculate each user's time to purchase duration** and\n",
    "  2. **find the tendency of user view-purchase duration** (please use a proper measure of central tendency).\n",
    "- Time to purchase duration is defined as the time difference between `view` event and `purchase` event. Consider only the earliest view and purchase.\n",
    "- The ouput should include `user_id` and their `view_purchase_duration` in minutes.\n",
    "\n",
    "**Dataset**\n",
    "- Please download the dataset in [here](https://drive.google.com/file/d/1GfFkxIbAivdY8bqbFbARCiyTzIuooKvV/view?usp=sharing)\n",
    "- The actual data source is [here](https://www.kaggle.com/datasets/mkechinov/ecommerce-events-history-in-electronics-store/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtIXg3yFvwEa"
   },
   "source": [
    "## Expected Output\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQbxs0kcgUT9"
   },
   "source": [
    "The output should be:\n",
    "```\n",
    "Data shape : (7847, 2)\n",
    "Summary of user's view to purchase duration : 4.7 minutes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNWZiCNNgWdo"
   },
   "source": [
    "With the sample of final data\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=159zrsppCuawgqn9q0e1B63KJzqe9Pvz9\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtQscdIlvwEb"
   },
   "source": [
    "## Answer\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDbosWUEvwEb"
   },
   "source": [
    "- Provide the code for getting the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVhYpW51hnVV"
   },
   "outputs": [],
   "source": [
    "# Write your code in here\n",
    "# Provide your code with sufficient comment on the wrangling processes"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4ukEolUB1yrn",
    "AcUiUO9e419L",
    "l8ZTkUY1DXce",
    "r44bj8r2m5Qn",
    "__nUZINgiFuz",
    "YBioio27iFuz",
    "ctEeOVMsiFu0",
    "UfXLyzAziFu2",
    "zO-1ez6Ypm8y",
    "liOhVqR0pm8z",
    "IH8qSK1EcmE5",
    "Fnzs051zpm80",
    "NZghty1lvwEZ",
    "naXaeZLDvwEa",
    "DtIXg3yFvwEa",
    "AtQscdIlvwEb"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
